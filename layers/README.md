# Introduction √† la biblioth√®que **Centaure**

Tout ce qui se trouve dans le dossier layers est le code de ce que j'appelle la biblioth√©que Centaure (Centaure est le nom du projet). Ce README documente donc ce code.

La biblioth√®que **Centaure** contient un ensemble de classes et de fonctions servant √† la supervision en masse d'√©quipements r√©seau. C'est une biblioth√©que de conception d'outil de supervision.
Ses fonctionnalit√©s principales incluent :

- Le **requ√™tage en masse** d‚Äôun ensemble de machines sur un r√©seau.
- La **le traitement d‚Äôinformations**.
- L'**√©coute de traps**.
- L‚Äô**enregistrement** de ces donn√©es dans des bases.
- La **gestion d'alerteurs**.

## Petite introduction (Quand et pourquoi utiliser la biblioth√®que Centaure ?)

Supposons que vous disposiez d‚Äôune base de donn√©es listant des machines d‚Äôun r√©seau, avec pour chaque machine :

- `nom_machine`
- `IP`
- √âventuels champs suppl√©mentaires li√©s √† l‚Äôacc√®s r√©seau (cl√© d‚Äôauthentification, etc.)

Si vous souhaitez :

1. R√©cup√©rer un ensemble de donn√©e pour chaque machine.
2. Enregistrer ces donn√©es en base dans un format structur√©.

Alors **Centaure** pourra r√©pondre √† vos besoins.
Cependant, pour ce sc√©nario simple, vous trouverez probablement d'autres outils √©galement.

Partons des m√™mes hypoth√®ses que pr√©c√©demment, mais ajoutons que :

- Chaque machine poss√®de un **type** (`type_machine`).
- Vous avez potentiellement une deuxi√®me base listant :

  - Des **OID**
  - Le **nom de la m√©trique**
  - Le **type de machine** associ√© √† cet OID

**Sch√©ma des tables :**

**Table `machines`**

| nom_machine     | IP         | type_machine | ... |
| --------------- | ---------- | ------------ | --- |
| 134401-AE-HUA-1 | 10.90.0.2  | Huawei       | ... |
| 130320-AE-ELT-1 | 10.90.0.30 | Eltek        | ... |
| ...             | ...        | ...          | ... |

**Table `oid_m√©triques`**

| oid             | nom_m√©trique     | type_machine |
| --------------- | ---------------- | ------------ |
| 1.3.6.1.2.1.1.3 | uptime_systeme   | Huawei       |
| 1.3.6.1.2.1.2.2 | trafic_interface | Eltek        |
| ...             | ...              | ...          |

**Objectif :**

- Pour chaque machine, contacter uniquement les OID correspondant √† son type.
- Associer chaque valeur √† une m√©trique avec un nom personnalisable.
- Avoir un contr√¥le total sur la structure de la base o√π les r√©sultats sont enregistr√©s, et pouvoir utiliser des bases de donn√©es MySQL.

**Centaure** a √©t√© pens√© pour repondre √† ces objectifs, et sera donc parfaitement adapt√©e pour ce cas.

## Guide de d√©marage (_Get Started_)

Je reconstruis dans cette partie l'outil de collecte SNMP, √©tape par √©tape.

Pour commencer, voyons comment utiliser **Centaure** pour une collecte de donn√©e dans le sc√©nario du **cas n¬∞2** vu en introduction :

```python
# Import des classes principales
from layers.scrapper.BaseScrapper import BaseScrapper
from layers.request_handler.SNMPRequestHandler import SNMPRequestHandler
from layers.database_manager.MySQLManager import MySQLManager
import mysql.connector

def load_machines_from_db():
    """
    R√©cup√®re la liste des machines depuis la base MySQL.
    Retourne une liste de dictionnaires au format attendu par BaseScrapper.
    """

    db_config = {
        "host"="localhost",
        "user"="root",
        "password"="password",
        "database"="machines_db"
    }

    conn = mysql.connector.connect(**db_config)
    cursor = conn.cursor()
    cursor.execute("SELECT NAME, AE_IP, AE_CONSTRUCTEUR FROM ATELIER_ENERGIE")
    rows = cursor.fetchall()
    cursor.close()
    conn.close()

    machines_list = [
        {
            "nom_machine": row[0],
            "ip": row[1],
            "type_machine": row[2]
        }
        for row in rows
    ]
    return machines_list

def load_oids_from_db():
    """
    R√©cup√®re la liste des OID √† interroger depuis la base MySQL.
    Retourne un dictionnaire :
    { type_machine: [ { 'oid': ..., 'metric': ... }, ... ] }
    """
    conn = mysql.connector.connect(**db_config)
    cursor = conn.cursor()
    cursor.execute("SELECT oid, nom_metrique, constructeur FROM METRIQUES")
    rows = cursor.fetchall()
    cursor.close()
    conn.close()

    oids_dict = {}
    for oid, metric, machine_type in rows:
        oids_dict.setdefault(machine_type, []).append({ # on classe les metriques par "machine_type"
            "oid": oid,
            "metric_name": metric
        })
    return oids_dict

class SNMPScrapper(BaseScrapper):
    def __init__(self, scrapping_data):
        super().__init__(scrapping_data) # on appelle la m√©thode parent

    def _load_default_requests(self):
        """
        Retourne un dictionnaire etiquet√© avec le type de machine, contenant pour chaque √©tiquette une liste de dictionnaire {'oid', 'metric'}.
        """
        return load_oids_from_db()

    def init_requester_with_recorder(self, machine_data):
        """
        classe abstraite qu'on doit obligatoirement r√©√©crire
        """
        address = machine_data['ip'] # d√©pend de la structure des dictionnaires renvoy√©s par load_machines_from_db
        name = machine_data['nom_machine']
        requests = self.load_requests(machine_data['type_machine']) # se base sur le dictionnaire retourn√© par _load_defaut_requests pour charger les bonnes donn√©es
        config = {'version': 2, 'community': 'public'} # ou autre chose, peut √™tre charg√© depuis la base de donn√©e en m√™me temps que address ou name si besoin. C'est RequestHandler qui impose les labels √† mettre dans le dictionnaire.

        data_manager = MySQLManager(
            SNMPRequestHandler(address, name=name, requests=requests, **config)
        ) # prend une instance de RequestHandler en entr√©e
        return data_manager # doit renvoyer l'intance, et peut aussi renvoyer alse pour signaler une erreur

if __name__ == "__main__": # on peut ensuite executer le code
    # Chargement des donn√©es des AE
    machines = load_machines_from_db()

    # Initialisation du scrapper
    scrapper = SNMPScrapper(machines)

    # Lancement de la collecte (avec sauvegarde des donn√©es)
    scrapper.run_all(save=True) # cette ligne peut bien s√ªr prendre un certain temps √† s'executer, en fonction du nombre de machine et de metrique √† historiser

    print("Collecte termin√©e et r√©sultats enregistr√©s.")
```

Analysons un peu ce code :

1. **Importations**
   Le code importe trois classes cl√©s :

   - `BaseScrapper` : classe m√®re g√©rant la logique g√©n√©rale de scrapping.
   - `SNMPRequestHandler` : g√®re les requ√™tes SNMP vers les machines.
   - `MySQLManager` : interface pour interagir avec une base MySQL.

2. **Fonction `load_machines_from_db()`**
   R√©cup√®re la liste des machines depuis la base de donn√©e.
   Retourne une liste de dictionnaires format√©s pour `BaseScrapper`.
   Chaque machine est repr√©sent√©e par un dictionnaire :

   ```python
   {"nom_machine": ..., "ip": ..., "type_machine": ...}
   ```

3. **Fonction `load_oids_from_db()`**
   Se connecte √† la base de donn√©e et r√©cup√®re les OID SNMP √† interroger, avec leur nom de m√©trique et le type de machine associ√©. Regroupe ces OID dans des dictionnaires au format {"oid": ... ,"metric_name": ... }

4. **Classe `SNMPScrapper`**
   H√©rite de `BaseScrapper` et personnalise certaines m√©thodes en utilisant SNMPRequestHandler et MySQLManager.
   On a notamment r√©√©crit la m√©thode \_load_default_requests, pour qu'elle importe depuis notre base de donn√©e les informations utiles au bon format (regroup√©s par `type_machine` dans un dictionnaire).

5. **M√©thode `init_requester_with_recorder()`**
   Configure un `SNMPRequestHandler` avec :

   - l‚Äôadresse IP,
   - le nom de la machine,
   - la liste d‚ÄôOID √† interroger,
   - la configuration SNMP (version, communaut√©, etc.).
     L‚Äôinstance est ensuite encapsul√©e dans un `MySQLManager` pour enregistrer les donn√©es.

6. **Bloc `if __name__ == "__main__":`**
   - Charge les machines depuis la base.
   - Initialise un scrapper SNMP.
   - Lance la collecte avec `run_all(save=True)`, qui interroge toutes les machines et stocke en base les r√©sultats.

> ce code ne fonctionnera pas sur HCAP5 pour trois raisons : la configuration de la base de donn√©e MySQL n'est pas la bonne, machine_data['type_machine'] ne contiendra pas les bonnes √©tiquettes m√™me avec la bonne configuration MySQL (elle contient par exemple l'√©tiquette 'Huawei', mais self.load_requests attend l'√©tiquette 'huawei') et la configuration fournie n'est valable que pour SNMPv2, donc seules les machines en SNMPv2 seront joignables avec cette configuration de toute fa√ßon.

üí° Notez qu'en fait, il existe d√©j√† une classe `SNMPScrapper` h√©ritant de `BaseScrapper`. L'id√©e dans la suite de ce _Get Started_ est de voir comment reconstruire et utiliser ce SNMPScrapper.

Pour expliquer le fonctionnement exacte de la classe SNMPScrapper tel qu'elle est impl√©ment√©e, nous allons devoir voir un certains nombre d'√©l√©ments suppl√©mentaires.

### personnaliser la configuration SNMP

Supposons maintenant que les √©l√©ments de configuration r√©seau ou SNMP (SNMPv2 ou v3, chiffrement AES ou DES,...) ne sont pas dans votre base de donn√©es.

Dans le code pr√©c√©dent, nous d√©finissons et utilisons deux m√©thodes, \_load_default_requests et load_requests, qui permettent de personnaliser les requests en fonction d'un champ sp√©cifique (ici le constructeur).

Il existe en fait deux m√©thodes sym√©triques √† \_load_default_requests et load_requests. C'est les m√©thodes \_load_default_config et load_config. En utilisant ces deux m√©thodes, on peut tout-√†-fait cr√©er une base de donn√©e avec les sp√©cifications r√©seau (SNMPv2 ou v3, community, ect...), mais on peut aussi plus simplement cr√©er "√† la main" un dictionnaire de configuration avec autant d'entr√©e que n√©cessaire, et le faire renvoyer par \_load_default_config.

C'est ce qu'on va faire ici, mais plut√¥t que de le d√©finir directement dans la m√©thode, cr√©ons un fichier de config √† la racine du projet, `config.py`, et d√©finissons dans ce fichier de config une variable globale CONFIG, qui contiendra ce fameux dictionnaire de configuration.

Ajoutons autre chose : actuellement, ce code fait de l'enregistrement en base, mais quel est le format exacte des bases de donn√©e ? Pour aider le code (et pour d'autres raisons beaucoup plus pertinentes que nous verrons plus loin), vous pouvez fournir une liste des noms des colonnes des tables SQL √† MySQLManager, dans l'argument table_struct. Ajoutons √ßa.

Enfin, ajoutons de la gestion des logs. Quasiment toutes les classes de centaure offrent un moyen de personnaliser les logs qu'elles produisent. Pour ce faire, il faut leur fournir un objet Logger personnalis√© de la biblioth√©que standard logging.

> logging est une biblioth√©que standrard de gestion des logs en python. Elle contient notamment un objet appel√© logger, qui est capable de g√©rer des logs avec ses m√©thodes debug, warning, error... En cas de doute sur le fonctionnement de cette biblioth√©que, vous pouvez consulter la documentation : https://docs.python.org/3.9/library/logging.html. Vous trouverez aussi un exemple de code comment√© dans `domain/collection/manage_log.py`.

Compl√©tons le code pour rajouter tout √ßa :

```python
from config import CONFIG # on suppose qu'on a cr√©√© un dictionnaire nomm√© CONFIG dans le fichier config √† la racine du projet
from logging import Logger

class SNMPScrapper(BaseScrapper):
    def __init__(self, scrapping_data, logger: Logger = None): # ici on rajoute un param√®tre logger, pour permettre √† l'utilisateur d'en fournir un si besoin
        super().__init__(scrapping_data, logger = logger)

    def _load_default_requests(self):
        """
        Retourne un dictionnaire etiquet√© avec le type de machine, contenant pour chaque √©tiquette une liste de dictionnaire {'oid', 'metric'}.
        """
        return load_oids_from_db()

    def _load_default_config(self):
        """
        Retourne un dictionnaire etiquet√© avec le type de machine, contenant pour chaque √©tiquette une liste de dictionnaire {'oid', 'metric'}
        """
        return CONFIG # on a juste besoin de renvoyer √ßa

    def init_requester_with_recorder(self, machine_data):
        """
        classe abstraite qu'on doit obligatoirement r√©√©crire
        """
        address = machine_data['ip'] # d√©pend de la structure des dictionnaires renvoy√©s par load_machines_from_db
        name = machine_data['nom_machine']
        requests = self.load_requests(machine_data['type_machine']) # se base sur le dictionnaire retourn√© par _load_defaut_requests pour charger les bonnes donn√©es
        config = self.load_config(machine_data['type_machine']) # on rajoute le chargement de la config
        # config ici peut par exemple √™tre un dictionnaire du type {'version': 3, 'auth_protocol': "MD5", 'priv_protocol': "AES",... }

        data_manager = MySQLManager(
            SNMPRequestHandler(address, name=name, requests=requests, **config, logger=self.logger), # on transmet notre logger personnalis√©, qui est dans self.logger, √† ces instances
            table_struct = ['datetime', 'metric_index', 'value'],
            logger = self.logger # on transmet notre logger personnalis√©
        ) # prend une instance de RequestHandler en entr√©e
        return data_manager # doit renvoyer l'intance, et peut aussi renvoyer False pour signaler une erreur
```

> En v√©rit√©, il y a encore quelques petites diff√©rences entre ce code et le v√©ritable code de SNMPScrapper. En fait, actuellement dans le code sur HCAP5, les requests faites (donc les oids) d√©pendent uniquement du constructeur, mais la config d√©pend quant-√†-elle du constructeur ET du mod√®le (du champ modele en base). On cr√© donc dans le dictionnaire scrapping_data un champ `requests`, qui contient le constructeur en minuscule, et le champ `config`, qui contient un string au format constructeurMODELE. La variable CONFIG dans config.py est de fait bien un dictionnaire etiquet√©e avec des strings au format constructeurMODELE. Je vous invite d'ailleurs √† consulter le fichier config.py si vous voulez mieux comprendre ce point. Pour les requests, on etiquette avec le premier mot du champ 'constructeur' en minuscule.

Comme √©voqu√© pr√©c√©demment, vous pouvez √©videmment √©galement stocker la config dans une base de donn√©e, ou √©crire directement le dictionnaire dans _load_default_config. Notez que load_config renvoie la valeur qu'elle re√ßoit sans la modifier si c'est une liste, un dictionnaire ou un tuple. load_resquests renvoie la valeur sans la modifier uniquement si c'est une liste, et renvera None si elle re√ßoit un dictionnaire ou un tuple. Si c'est un string, les deux fonctions vont chercher une cl√© correspondante dans ce qui est renvoy√© par \_load_default_\*, et renvoyer cette valeur, ou None si elles ne trouvent rien.

> Note 1 : les m√©thodes \_load_default* ne sont appel√©es qu'une seule fois (par instance de scrapper), lors du premier appel √† la fonction load* correspondante avec un string en entr√©e.

> Note 2 : les fonctions load\* ne renvoient jamais d'erreur. Elles log une erreur et renvoient None en cas de probl√®me.

> Note 3 : Pourquoi seules les listes sont renvoy√©es tel quel par load_requests ? Parce que requests doit ensuite √™tre fourni √† un RequestHandler, et que RequestHandler attend en entr√©e une liste (de dictionnaire), et rien d'autre. La config est elle g√©r√©e par init_requester_with_recorder directement, donc le format est plus libre. Notez par contre que la m√©thode \_load_default_config (tout comme \_load_default_requests d'ailleurs) doit renvoyer un dictionnaire, c'est ce qu'attend load_config quand elle l'appelle.

### le champ options

Et maintenant si vous voulez m√©langer des configurations √©crites √† la main et des √©l√©ments de configuration qui sont dans votre base de donn√©es, comment faire ?

En effet vous pourriez avoir une configuration g√©n√©rale de ce type :
SNMPv3, chiffrement AES, authentification SHA, mais avec des mots de passe et/ou nom d'utilisateur (username) sp√©cifiques pour chaque machine.

En fait, on pourrait tout-√†-fait g√©rer √ßa √† la main : il suffirait de r√©√©crire la m√©thode init_recorder_with_requester, et d'entrer dans requester les champs soit les champs que vous voulez.

Notez cependant qu'il existe une alternative un peu plus "propre" pour faire √ßa, et qui est utilis√©e dans le code, en utilisant le champ _options_ de SNMPRequestHandler :
Vous pouvez, dans votre fichier de config, noter entre deux '\_\_' certains champs. Vous pourrez ensuite fournir ces champs √† SNMPRequestHandler. Si vous fournissez le champ \_\_username\_\_ pour la valeur username en entr√©e de requestHandler, celui-ci ira chercher le champ 'username' dans le champ options fourni en entr√©e (qui doit √™tre un dictionnaire). S'il le trouve, il va remplacer username par la valeur li√© √† la cl√© 'username' dans le champ options.

```python
machine_data = {
    'name': '134401-AE-HUA-1',
    'username': '1344011'
}
data_manager = MySQLManager(
    SNMPRequestHandler(address, name='__name__', requests=requests, username='__username__', ... , options=machine_data, logger=self.logger), # on rajoute options=machine_data, qui nous permettra d'utiliser la notation __label__ pour tout les labels contenus dans machine_data. Ici, username sera remplac√© par 1344011 dans SNMPRequestHandler.
    logger = self.logger
) # prend une instance de RequestHandler en entr√©e
```

Notez que le champ `options` peut √©galement √™tre utilis√© par toute autre m√©thode de requestHandler et m√™me de dataManager (pour rappel, dataManager peut prendre en entr√©e un RequestHandler, et d√®s lors peut donc acc√®der √† tout ses attributs).
En pratique, le champ options est effectivement utilis√© dans MySQLManager. On appelle options['id'] pour g√©n√©rer les noms de table. Vous devez donc fournir √† cette classe des instances de RequestHandler avec un champ options contenant au moins la cl√© 'id'.

> Le `username` n'est pas directement dans la base SQL Historica. En fait, dans le code sur HCAP5, ce champ est g√©n√©r√© √† partir du nom des AE dans la fonction qui g√©n√®re le champ scrapping_data (dans domain/collection/generate_dictionnary.py).

### les op√©rateurs

Mais imaginons maintenant que vous avez le probl√®me suivant : vous ne voulez pas enregistrer en double certaines informations dans votre base de donn√©es pour ne pas la surcharger. Ou alors vous voulez appliquer un pr√©-traitement √† vos donn√©es, par exemple d√©chiffrer des donn√©es encod√©es en hexad√©cimal, avant de les enregistrer en base, et ce sur certaines donn√©es sp√©cifiques uniquement. Vous pourriez alors vouloir utiliser les op√©rateurs.
Les op√©rateurs (ou operators dans le code) sont des fonctions qui s'appliquent sur les donn√©es avant leur enregistrement. C'est une mani√®re de pr√©-traiter les donn√©es enregistr√©es en base. La gestion des op√©rateurs se fait dans BaseDataManager, et n√©cessite deux √©l√©ments :

- d'une part, vous devez fournir √† BaseDataManager, dans la liste des requests, plus sp√©cifiquement au niveau du dictionnaire de la m√©trique √† traiter, un champ operators, contenant un string repr√©sentant une fonction.
- d'autre part vous devez cr√©er un dossier operators √† la racine de votre projet et inclure un fichier col_operators.py. Vous devez ensuite √©crire une fonction dans ce fichier avec EXACTEMENT le m√™me nom que le string soumis dans le dictionnaire correspondant √† la request, et avec le squelette suivant :

```python
def func(metric: str, values: list[dict], connector):
    # contenu de la fonction
    return metric, values
```

o√π :

- metric est un string, le nom de la metrique, qui va principalement d√©finir le nom de la table dans laquelle la donn√©e va √™tre enregistr√©e (le nom sera au format metrique_ID)
- values est une liste de dictionnaire, o√π chaque dictionnaire a un format du type {'datetime':12121212, 'metric_index': 1, 'value': '12'} (les cl√©s correspondent √† des colonnes en base, et contiennent la valeur correspondante qui sera enregistr√©e).
- connector est un objet contenant un champ connect (connector.connect) et cursor (connector.cursor) de la biblioth√©que mysql. Ce champ permet surtout de faire (si besoin) des requ√™tes en base dans les operateurs sans avoir √† se reconnecter √† la base SQL (la connexion √©tant d√©j√† ouverte), donc en limitant les pertes de temps.
- vous renvoyez un champ values contenant les valeurs que vous voulez enregistrer, et qui peut valoir 0 ou None si vous ne voulez finalement pas enregistrer de valeur. Vous devez √©galement renvoyer le champ metric (on renvera en g√©n√©ral celui qu'on a re√ßu en entr√©e, mais vous pouvez bien s√ªr le modifier si besoin).

Avant l'enregistrement en base de chaque m√©trique, BaseDataManager v√©rifie s'il existe un champ operators dans le dictionnaire de la request avec un contenu valide. Si c'est le cas, il tentera de charger une fonction depuis operators/col_operators avec exactement le m√™me nom, et l'appliquera aux donn√©es.

> Note 1 : operators peut √©galement √™tre une liste, ou un long string avec plusieurs noms s√©par√©s par des virgules ou des ';', et dans ce cas l'instance se chargera d'en extraire une liste via du regex. Elle appliquera tout les op√©rateurs les uns √† la suite des autres, dans l'ordre dans lequel ils ont √©t√©s fournis.

> Note 2 : le nom du fichier col_operators est personnalisable. Il suffit d'indiquer √† l'instance de la classe dans quel fichier elle doit aller chercher les op√©rateurs. Elle cherchera par contre toujours le fichier renseign√© dans le dossier operators √† la racine du projet. En pratique, on utilise bien le fichier col_operators pour les op√©rations de collecte en base.

> Note 3 : Comme d√©j√† √©voqu√©, les operateurs sont g√©r√©s par MySQLManager, ou plus pr√©cisement par sa classe parente BaseDataManager. Le principe est le suivant : tout les operateurs du fichier indiqu√© sont import√©s lors de l'initialisation, puis la m√©thode load_operators est appel√©e quand des operateurs doivent √™tre appliqu√©s et renvoie une liste d'operateur (d'objet Callable) ou False si elle n'a pas rien trouver ou s'il n'y a aucun operateur √† appliquer, les operateurs sont ensuites tous appliqu√©s aux donn√©es dans la methode qui a appel√© load_operators (en g√©n√©ral run_metric). A noter que la m√©thode load_operators n'est pas optimale en terme de temps d'execution (cherche les op√©rateurs √† partir du nom de la m√©trique donc doit parcourir toute la liste des metriques), et qu'une am√©lioration future pourrait impliquer de l'am√©liorer un peu (m√™me si son temps d'execution est probablement tr√®s faible par rapport au temps des requ√™tages et enregistrements en base).

### SNMPScrapper, version finale

On a maintenant vu tout les √©l√©ments essentiels √† comprendre pour cr√©er la classe SNMPScrapper. Voyons le code complet :

```python
# Import des classes principales
from layers.scrapper.BaseScrapper import BaseScrapper
from layers.request_handler.SNMPRequestHandler import SNMPRequestHandler
from layers.database_manager.MySQLManager import MySQLManager
import mysql.connector
from config import get_constructor_string, get_config_from, ae_db_config as db_config
import re

def load_machines_from_db():
    """
    R√©cup√®re la liste des machines depuis la base MySQL.
    Retourne une liste de dictionnaires au format attendu par BaseScrapper.
    """
    conn = mysql.connector.connect(**db_config)
    cursor = conn.cursor(dictionary=True)  # Retourne directement des dictionnaires
    cursor.execute("""
        SELECT NAME, AE_IP, AE_CONSTRUCTEUR, AE_TYPE, ID
        FROM ATELIER_ENERGIE
        WHERE AE_SUP = 1
    """)
    rows = cursor.fetchall()
    cursor.close()
    conn.close()

    machines_list = [
        {
            "name": row["NAME"],
            "address": row["AE_IP"],
            "requests": get_constructor_string(row["AE_CONSTRUCTEUR"]), # l'√©tiquette des requ√™tes
            "config": generate_config_string(row["AE_CONSTRUCTEUR"], row["AE_TYPE"]), # l'√©tiquette de la config
            "username": re.sub(r'\D', '', row["NAME"])  # garde uniquement les chiffres
        }
        for row in rows
    ]
    return machines_list


def load_oids_from_db():
    """
    R√©cup√®re la liste des OID √† interroger depuis la base MySQL.
    Retourne un dictionnaire
    """
    conn = mysql.connector.connect(**db_config)
    cursor = conn.cursor()
    cursor.execute("SELECT oid, nom_metrique, constructeur, operateurs FROM METRIQUES")
    rows = cursor.fetchall()
    cursor.close()
    conn.close()
    oids_dict = {}
    for oid, nom_metrique, constructeur, operateurs in rows:
        oids_dict.setdefault(constructeur, []).append({ # on classe les metriques par "constructeur"
            "oid": oid,
            "metric_name": nom_metrique,
            "operator": operateurs
        })
    return oids_dict

class SNMPScrapper(BaseScrapper):
    def __init__(self, scrapping_data, logger=None):
        super().__init__(scrapping_data, logger=logger)

    def _load_default_requests(self):
        return load_oids_from_db()

    def init_requester_with_recorder(self, machine_data: Dict[str, str]):
        if not 'address' in machine_data or not 'name' in machine_data or not 'requests' in machine_data or not 'config' in machine_data:
            return False

        address = machine_data['address']
        name = machine_data['name']
        requests = self.load_requests(machine_data['requests'])
        config = self.load_config(machine_data['config'])

        if isinstance(config, dict):
            recorder = MySQLRecorder(
                SNMPRequestHandler(address, name=name, requests=requests, **config, options=machine_data, logger=self.logger),
                table_struct = collection_table_structure,
                logger = self.logger
            )
            self.logger.info("Dans init_requester_with_recorder (SNMPScrapper) : message avec les informations X ou Y")
            return recorder
        else:
            return False

if __name__ == "__main__": # on peut ensuite executer le code

    # Chargement des donn√©es des AE
    machines = load_machines_from_db()

    # Initialisation du scrapper
    scrapper = SNMPScrapper(machines)

    # Lancement de la collecte (avec sauvegarde des donn√©es)
    scrapper.run_all(save=True) # cette ligne peut prendre un certain temps √† s'executer, en fonction du nombre de machine et de metrique √† historiser

    print("Collecte termin√©e et r√©sultats enregistr√©s.")
```

> Ce code fonctionne bien, √† condition de l'executer dans le dossier /data/sdm_centaure, pour qu'il puisse acc√©der √† config.py. Il r√©alise une collecte compl√®te sur tout les AE r√©cup√©r√©s, ce qui peut prendre facilement 10 √† 20 secondes. Ici, je n'ai pas fourni d'objets logger √† mon code, l'execution affichera donc tout les logs (comportement par d√©faut).

L'historique du projet et des bases de donn√©e fait que les champs servant de cl√© entre les bases ('Vertiv / Emerson', 'Eltek', ect...) ne sont pas exactement les m√™mes entre diff√©rentes bases. On a par exemple la correspondance suivante entre les constructeurs :

    {
        'Huawei': 'huawei',
        'Eltek': 'eltek',
        'Vertiv / Emerson': 'vertiv'
    } // Notez qu'on prend en fait le premier mot en minuscule

Vous trouverez √† la fin de config.py quelques fonctions qui servent justement √† assurer cette correspondance, et qu'on utilise ci-dessus dans le code.

Par ailleurs, les champs table_struct utilis√©s sont √©galement tous d√©finis dans config.py en pratique, et non directement dans le code.

Bref, la conclusion de toute cette partie : quand vous avez un probl√®me sur la collecte, commencez par aller voir dans config.py !

## Quelques compl√©ments sur MySQLManager

On √©voque beaucoup cette classe depuis le d√©but, sans rentrer dans les d√©tails de son fonctionnement. Je reviens donc sur les √©l√©ments centreaux de cette classe dans cette partie, d'autant plus qu'elle est utilis√©e dans quasiment toutes les applications m√©tiers (collecte, gestion des traps, alarmes,...)

La classe MySQLManager g√®re en fait les int√©ractions avec la base de donn√©e. L'int√©r√™t d'avoir une classe d√©di√©e est d'autant plus fort que la structure de la base de donn√©e n'aide pas forcement √† int√©ragir avec.

La classe MySQLManager est donc capable :

- D'enregistrer des donn√©es en base en masse, via sa m√©thode save
- De modifier des donn√©es en base en masse, via sa m√©thode update
- De r√©cup√©rer des donn√©es en base avec sa m√©thode fetch
- De supprimer des donn√©es en base avec delete

Elle g√®re les donn√©es par machines (AE) et non par table. C'est d'ailleurs tout l'int√©r√™t de ces classes. Elle va √™tre capable d'int√©ragir avec toutes les tables associ√©es √† une m√™me machine sans que l'utilisateur n'ai besoin de se pr√©ocuper ou m√™me de connaitre la structure des tables et bases de donn√©e !

Cette classe est construite sur deux classes parentes :

- BaseDataManager : classe abstraite qui impl√©mente un certains nombre d'√©l√©ment de logique ind√©pendemment du type de base (MySQL) utilis√©
- MySQLRecorder : h√©rite de BaseDataManager, et impl√©mente la m√©thode save (plus exactement \_save_entry, j'y reviens plus loin) pour permettre les sauvegardes en base. En pratique, on utilise cette classe dans l'outil de collecte plut√¥t que MySQLManager, puisqu'on a uniquement besoin des op√©rations d'enregistrement en base (save).
- MySQLManager : h√©rite de MySQLRecorder, donc peut utiliser la m√©thode save. Impl√©mente les m√©thodes, update, fetch, et delete.

Le principe g√©n√©ral de cette classe est le suivant :
La classe poss√®de un attribut data (qui est au format {'metrique_1': [{'datetime': 121212, 'value': '234', ...}, ... ], ... }). A chaque fois qu'elle veut faire une op√©ration en base, elle :

1. g√©re l'ouverture de la connexion √† la base de donn√©e -> self.run
2. parcourt chaque metrique dans data -> self.run
3. g√©re les operateurs pour chaque liste (values) associ√©e √† chaque metrique -> self.run_metric
4. parcourt la liste apr√®s action des operateurs -> self.run_metric
5. pr√©traite chaque entr√©e (value) pour en extraire une entry -> self.run_metric
6. appelle une m√©thode sp√©cifique d√©finie dans une des classes enfants pour faire l'op√©ration en base voulue (les quatres m√©thodes sont \_fetch_entry, \_save_entry, \_update_entry, \_delete_entry)

O√π entry est une liste du type :

    [
        {
        'column_name': 'datetime',
        'column_type': self.SQL_format['datetime'], // INT NOT NULL DEFAULT 0
        'value': value
        },
        {
        'column_name': 'datetime',
        'column_type': self.SQL_format[label], // INT NOT NULL DEFAULT 0
        'value': value
        },
        {
        'column_name': 'datetime',
        'column_type': self.SQL_format[label], // INT NOT NULL DEFAULT 0
        'value': value
        }
    ]

> Ok, mais qu'est ce qu'est le self.SQL_format ci-dessus ?

Voyons √ßa, et tant qu'√† faire, voyons l'ensemble des √©l√©ments d'entr√©e de MySQLRecorder et MySQLManager (ils ont les m√™mes).

Voici l'ensemble des attributs d'entr√©e de MySQLRecorder et MySQLManager :

```python
def __init__(self,
    instance: Union[RequestHandler, None] = None,
    data: Any = None,
    database_config: Dict[str, str] = None,
    tables_id: Union[str, int, None] = None,
    table_struct: Union[List[str], None] = None,
    connector: Any = None,
    SQL_format: Union[Dict[str, str], None] = None,
    auto: bool = False,
    name: str = "",
    logger = None
)
```

Voyons ce que fait chaque √©l√©ment :

**instance :**
Doit recevoir une instance d'un RequestHandler. On a d√©j√† utilis√© cet argument dans des codes plus haut, pour la classe SNMPScrapper. Quand vous fournissez un champ instance, l'instance se retrouvera enregistr√©e dans l'attribut self.object. Vous devrez collecter des donn√©es avec cette instance self.object (par exemple en lan√ßant self.object.run(), voir section d√©di√©e aux RequestHandler plus loin). Vous pourrez ensuite, par exemple, enregistrer directement les donn√©es r√©cup√©r√©es par self.object simplement en appelant la m√©thode save. Elle ira directement r√©cup√©rer les donn√©es sauvegard√©es dans self.object.

**data :**
Vous pourriez aussi vouloir faire des enregistrements en base, modifications, ect... sans passer par une instance de RequestHandler. Vous pouvez alors directement fournir vos donn√©es dans le champ data.
Le format attendu par data est le suivant :

    {
        'metrique_1': [
            {'datetime': 121212, 'metric_index': 0, 'value': '432'},
            ...
        ],
        ...
    }

Vous ne voudrez donc √† priori jamais fournir un champ data et un champ instance en entr√©e de MySQLManager. Notez que les valeurs dans data seront potentiellement √©cras√©es quand vous appelerez object.run().

> Remarque : vous pourrez acc√©der √† data en appelant self.data apr√®s l'initialisation de votre instance. De m√™me, si vous utilisez une instance, vous pourrez voir les donn√©es r√©cup√©r√©es dans self.data apr√®s lancement des requ√™tes sur la machine (avec self.object.run() par exemple). Notez que vous ne pouvez pas modifier √† la main le champ data (self.data = truc renvera une erreur). Si vous devez absolument modifier data, vous devez appeler self.set_data(nouvelle_valeur_que_vous_voulez_donner_a_data).

**database_config :**
C'est tout simplement les √©l√©ments de connexion √† la base de donn√©e. Vous n'aurez pas besoin de l'utiliser la plupart du temps car quand rien n'est fourni, les instances de MySQLRecorder vont chercher la configuration appel√©e `db_config` dans config.py.

**tables_id :**
Attend un int (un ID) correspondant √† un AE sp√©cifique (c'est son ID dans la table ATELIER_ENERGIE). Essentiel sinon le code ne sera pas identifier quelles tables correspondent √† la machine sur laquelle on fait des op√©rations ! Le seul cas ou on peut s'en passer : si vous avez fourni une entr√©e `instance` contenant un champ options avec {'id': ID}.

**SQL_format :**
Le fameux ! Attend un dictionnaire, avec comme label (key) le nom des colonnes en table, associ√© au type de ces colonnes. Si rien n'est fourni (c'est quasiment tout le temps le cas), va se set avec le dictionnaire `database_struct_config` de config.py. Voyons un extrait de ce dictionnaire (que vous pouvez retrouver dans le fichier config.py) :

    { # structure des donn√©es en base
        'datetime': 'INT NOT NULL DEFAULT 0',
        'metric_index': 'SMALLINT NOT NULL DEFAULT 0',
        'value': 'VARCHAR(63)',
        ...
    }

En fait, MySQLRecorder (donc √©galement MySQLManager) va comme vu pr√©c√©demment pr√©traiter les donn√©es en leur associant un type (INT, VARCHAR, ect...) gr√¢ce √† SQL_format, ce qui lui pemet de faire de la gestion d'erreur SQL. Plus pr√©cisemment, elle g√®re les erreurs 'table not exists' et 'columns not exists'. Pour ce faire, elle va tout simplement cr√©er la table (ou les colonnes dans la table) en se basant sur entry, qu'elle re√ßoit en entr√©e, et sur les types qu'elle contient. C'est l√† l'utilit√© du champ SQL_format !

**table_struct :**
Attend une liste de string. Permet d'imposer (de renseigner) la structure des tables en base. Il suffit de fournir une liste contenant le nom des colonnes, correspondant √† des labels dans SQL_format (ou database_struct_config si SQL_format n'est pas fourni). Ce champ force l'instance √† respecter une structure de table sp√©cifique quand elle va cr√©er des tables ou des colonnes dans les tables. Si cet argument n'est pas fourni, l'instance va se paser sur le contenu de entry pour construire les tables (ce qui veut dire que si un entry contient par erreur une valeur en plus, une nouvelle colonne sera cr√©√©e pour stocker cette valeur. Si vous pr√©ciser un table_struct, la valeur en trop dans entry sera ignor√©e).
Il est probabablement toujours bon de renseigner un table_struct quand vous utilisez MySQLRequester ou MySQLManager si vous savez quelle structure doit avoir votre base.

**connector :**
Permet de renseigner un objet connector, (donc contenant connector.connect et connector.cursor de la librairy mysql.connector en python). J'en profite d'ailleurs pour pr√©ciser qu'un constructeur de connector est disponible dans `layers/database_manager/connector/MySQLConnector.py`.
Le connector peut aussi √™tre renseign√© dans la m√©thode save, fetch, ect... au moment ou on l'appelle, et c'est plut√¥t cela qu'on fera la plupart du temps. Vous pouvez cependant du coup le renseigner dans le constructeur, et il sera alors utilis√© dans toutes les op√©rations en base faites.
Notez que m√™me si vous ne renseignez rien, vous pourrez quand m√™me utiliser les m√©thodes save, fetch... sans probl√®me. Ces m√©thodes appeleront la m√©thode interne open_database qui se chargera d'ouvrir la connexion √† la base de donn√©e √† partir de `db_config` dans config.py (ou du database_config que vous aurez fourni en entr√©e le cas √©ch√©ant). Il s'agit juste de diff√©rentes mani√®res possibles de g√©rer la connexion √† la base de donn√©e.

**auto :**
Permet de forcer la connexion √† la base de donn√©e lors de l'initialisation si pass√© √† True (False par d√©faut). √ßa avait de l'int√©r√™t dans une vielle version du code, mais √ßa n'en a quasiment plus maintenant sauf cas tr√®s particulier, et je ne conseille pas de l'utiliser (notez qu'une connexion SQL se referme souvent apr√®s quelques secondes d'inactivit√©, il vaut donc mieux ouvrir la connexion au dernier moment quand c'est possible, donc lors de l'appel √† save, fetch, ect...).

**name :**
Permet de renseigner un nom, qui sera accessible dans self.name et qui apparaitra dans certains logs d'erreur (c'est pratique si vous instanciez des disaines d'instance dans un m√™me code pour comprendre d'ou vient un √©ventuel probl√®me, cela dit c'est le seul int√©r√™t de ce champ). Si un champ `instance` est fourni, prend le nom associ√© √† cette instance.

**logger :**
D√©j√† √©voqu√©, vous pouvez fournir un objet logger pour personnaliser la gestion des logs.

Pour compl√©ter ce tableau, voyons √©galement les arguments d'entr√©e des m√©thodes save, fetch, ect... Ces m√©thodes appellent toutes la m√©thode run avec diff√©rents arguments. Le fonctionnement de self.run a d√©j√† √©t√© √©voqu√© plus haut, mais voyons ici quelques variantes √† travers la documentation de ces m√©thodes.

Voici, pour commencer, le code d√©finissant ces m√©thodes (que vous retrouverez dans le fichier `layers/database_manager/BaseDataManager.py`) :

```python
def save(self, check_operator: bool = True, connector: Any = None) -> bool:
    return self.run(operation_type='_save_entry', check_operator=check_operator, connector=connector)

def fetch(self, where: str = None, check_operator: bool = False, prepare = True, once = False, connector: Any = None) -> List[Dict[str, Any]]:
    return self.run(operation_type='_fetch_entry', where=where, check_operator=check_operator, prepare=prepare, once=once, connector=connector)

def update(self, where: str = None, check_operator: bool = True, connector: Any = None) -> bool:
    return self.run(operation_type='_update_entry', where=where, check_operator=check_operator, connector=connector)

def delete(self, where: str = None, check_operator: bool = False, prepare = True, once = False, connector: Any = None) -> bool:
    return self.run(operation_type='_delete_entry', where=where, check_operator=check_operator, prepare=prepare, once=once, connector=connector)
```

Voyons l'ensemble des arguments qui apparaissent :

**check_operators :**
bool√©en, True par d√©faut. Permet, si on le passe √† False, d'emp√©cher l'action des operateurs, ce qui rend au passage l'execution √† peine plus rapide. A noter que cet argument n'a pas vraiement d'int√©r√™t, et n'agira probablement pas de la mani√®re dont vous vous y attendez, pour les m√©thodes fetch et delete. Il est d'ailleurs √† False par d√©faut pour ces deux m√©thodes.

**connector :**
objet connector. C'est surtout utile quand on a plusieurs MySQLManager et qu'on veut optimiser le temps d'execution : on peut alors ouvrir la connexion en amont et passer la connexion d√©j√† ouverte √† chaque appel des m√©thodes fetch, save, update,...

**where :**
Attend un string. Permet de pr√©ciser une condition where (le string s'ajoutera √† la suite de la requ√™te SQL avec "WHERE " + where).
Petite particularit√©e : le string where est pr√©trait√© avant d'√™tre utilis√© dans la requ√™te, par la m√©thode `_treat_where` (de BaseDataManager), de mani√®re √† remplacer les √©l√©ments au format `__label__` par la valeur associ√©e au label dans chaque value. C'est particuli√®rement util dans certains cas pour update (vous pouvez par exemple faire des modifications en base en masse et de mani√®re pr√©cise en indiquant un `metric_index` sp√©cifique dans vos values et en fournissant un where = "metric_index = \_\_metric_index\_\_).

**operation_type :**
Argument d'entr√©e de run, qui vous peut-√™tre intrigu√©. Comme √©voqu√© pr√©cdemment, run est globalement juste une m√©thode qui itere sur une liste d'entr√©e, leur applique divers traitements, puis les envoient √† d'autres m√©thodes. Et bien operation_type est un string correspondant au nom de "l'autre m√©thode" √† laquel run (ou plus exactement run_metric la plupart du temps) va envoyer ses entr√©es trait√©es. La m√©thode cherche dans sa propre instance une m√©thode avec le m√™me nom et la charge pour lui fournir les donn√©es. Vous n'avez cependant en g√©n√©ral pas √† vous pr√©ocuper de ce champ.

**prepare :**
bool√©en. Emp√©che l'√©tape de pr√©paration des donn√©es quand il est √† False (renvoie une liste avec un dictionnaire vide √† la place des donn√©es attendues). Son utilit√©e est vue juste apr√®s.

**once :**
Modifie le fonctionnement de run quand il est True, son unique utilit√©e est vue juste apr√®s √©galement.

### quelques sp√©cificit√©es de fetch

MySQLManager a d'abord √©t√© pens√©e pour faire des enregistrements en base. Les autres op√©rationsont √©t√© ajout√©s progressivement au fil de l'eau. De fait la m√©thode fetch fonctionne sur le m√™me sch√©ma que la m√©thode save, Ce qui rend son fonctionnement particuli√®rement contre-intuitif, et qui la rend donc compliqu√©e √† utiliser.

> D'ailleurs, repenser le fonctionnement des recherches en base pour cette classe est √† mon avis un axe d'am√©lioration du code tr√®s pertinent. Il serait notamment int√©ressant de l'√©tendre pour pouvoir faire des requ√™tes avec des ORDER BY, LIMIT, ect...

Mon conseil :
La plupart du temps, quand on fait un SELECT, on voudra en fait juste r√©cup√©rer toutes les donn√©es v√©rifiant une certaine condition WHERE, qu'on pr√©cisera en clair (sans utiliser les notations type \_\_label\_\_). Dans ce cas, les codes suivants fonctionneront tr√®s bien.

Pour r√©cup√©rer les donn√©es li√©es √† plusieurs metriques sur un m√™me AE (c'est ce que vous voudrez faire la plupart du temps), vous pouvez utiliser le code ci-dessous :

```python
data_manager = MySQLManager(data = {'metrique_1': [ ... ], 'metrique_2': [ ... ], ... }, tables_id=ID) # ID : l'id correspondant √† l'AE dont vous voulez r√©cup√©rer les donn√©es.
# le champ data servira de r√©f√©rence pour savoir quelles metriques r√©cup√©rer
data_manager.fetch(where = "la condition sql que vous voulez", prepare = False, once = True) # on precise bien les arguments prepare = False et once = True. Ce code ira r√©cup√©rer les donn√©es li√©es √† toutes les metriques contenues dans data en respectant la condition where fournie. Vous pouvez aussi passer le where directement au constructeur : data_manager = MySQLManager(..., where = "La condition sql que vous voulez", ...)
print(data_manager.fetched_data) # contiendra un dictionnaire du type {'metrique_1': [{'datetime':121212, 'metric_index': 2, 'value': '54'}, ...], ... }
```

> J'en profite pour faire remarquer que les donn√©es de fetch s'enregistrent dans un attribut sp√©cifique, l'attribut fetched_data.

A noter que vous pouvez faire exactement la m√™me chose sans pr√©ciser once=True, mais qu'il faut dans ce cas fournir √† MySQLManager le champ `data={'metrique_1': [], 'metrique_2': [], ... }` (avec des listes vides).

Si vous voulez les donn√©es d'une seule m√©trique (donc d'une seule table) :

```python
data_manager = MySQLManager(data = { ... }, tables_id=ID) # ID : l'id correspondant √† l'AE dont vous voulez r√©cup√©rer les donn√©es.
# Ici, ce que vous indiquez dans data n'a strictement aucunes importances
data_manager.run_once('_fetch_entry', metric_name = nom_de_la_metrique_a_recuperer, where = "ce que vous voulez", prepare = False) # l√† encore, prepare = False permet d'√©viter certains comportements inatendus
```

Dans tout les cas, les donn√©es r√©cup√©r√©es seront accessibles dans data_manager.fetched_data au format :

    {
        'metrique_1': [
                {'datetime':121212, 'metric_index': 2, 'value': '54'},
                ...
            ],
        'metrique_2': [
            ...
        ],
        ...
    }

> Vous pouvez √©galement bien s√ªr cr√©er vos propres scripts pour faire des SELECT, et ce sera peut-√™tre la solution la plus simple dans certains cas, en particulier si vous voulez r√©cup√©rer les donn√©es li√©es √† une metrique pour chaque machine. Le code de Centaure fait l'inverse : il r√©cup√®re les donn√©es des metriques pour une machine sp√©cifique. Par exemple, si vous voulez r√©cup√©rer toutes les alarmes actives, le plus simple sera de faire un SHOW TABLES, puis de r√©cup√©rer toutes les tables au format alarme_ID, et de faire un SELECT avec alarme_active = 1 dans chaqu'unes de ces tables.

### Bug exploit pour faire une requ√™te ORDER BY ..

Il n'y a rien de pr√©vu nativement dans MySQLManager actuellement pour rajouter d'autres conditions √† la requ√™te (ORDER BY, LIMIT, ect... )

Notez cependant qu'il y a un 'bug' dans le fonctionnement de MySQLManager que vous pouvez exploiter pour rajouter ces √©l√©ments √† votre requ√™te :
En fait, il suffit de fournir une valeur de where du type where = "alarme_active = 1 ORDER BY start_time". Le string sera directement concat√©n√© au reste de la requ√™te : requete_sql + "WHERE" + where, et la requ√™te prendra donc en compte les commandes suppl√©mentaires. Attention par contre √† ne pas mettre un 'WHERE' au d√©but de votre string sans quoi il apparaitra deux fois et la requ√™te plantera !

> Bien s√ªr, comme √©voqu√© pr√©c√©demment, ajouter une solution plus perenne pour faire ce type de requ√™te dans le futur pourrait √™tre pertinent...

### Un point sur la m√©thode delete

delete est de loin la m√©thode la moins test√©e, car n'avait pas d'utilit√©e dans les applications m√©tiers d√©velopp√©es jusqu'√† maintenant. Elle soufre cependant visiblement des m√™mes probl√®mes que fetch, et il faut donc l'appeler avec les m√™mes arguments pour obtenir le r√©sultat souhait√©. Au del√† de ce point, je peux juste vous conseiller de tester de mani√®re appronfondie toute op√©ration faite avec cette m√©thode avant de la lancer sur la base (par exemple, et √† minima, en faisant un fetch avant avec les m√™mes arguments et en affichant le r√©sultat pour voir quelles metriques sont r√©ellement impact√©es).

## Quelques compl√©ments sur SNMPRequestHandler

Dans la continuit√© du point pr√©c√©dent, voyons quelques √©l√©ments g√©n√©raux sur SNMPRequestHandler.

Comme pour MySQLManager, SNMPRequestHandler g√©re une machine sp√©cifique, dans son cas pour les requ√™tes SNMP.

SNMPRequestHandler poss√®de un ensemble de m√©thode capable de faire des requ√™tes SNMP diverses, ainsi qu'une m√©thode de traitement des oid (capable de faire le lien entre des oids re√ßus en r√©ponse des requ√™tes, et des oids envoy√©es). Cette m√©thode est primordiale car elle permet de requ√™ter plusieurs oids en une seule fois, correspondant √©ventuellement √† des metriques diff√©rentes, et √† refaire le lien avec les metriques en question √† partir des oids dans la r√©ponse des requ√™tes. Elle fait aussi une sorte de "premier traitement" de la donn√©e, qui vise √† standardiser toutes les donn√©es r√©cup√©r√©es en les structurant au format attendu par les autres scripts ({'metrique': [{dictionnaire de donn√©e 1, dictionnaire de donn√©e 2, ... }, ... ]}).
La m√©thode run combine ces diff√©rentes m√©thodes pour r√©cup√©rer toutes les valeurs li√©es √† une s√©rie d'oid (plus exactement √† une serie de metrique pass√©es en entr√©e).

> La construction de la m√©thode run est tr√®s d√©pendante du type de machine √† contacter et de leur structure, et d√©pend globalement de consid√©rations li√©es au protocole SNMP. Par exemple, si on avait que des machines en SNMPv3, on pourrait faire une (unique) requ√™te get sur tout les oids, puis une (unique) requ√™te bulk (type de requ√™te SNMP) sur tout les oids sur lesquels le get a √©chou√©.

Il y a moins de points techniques √† voir sur le code, nous aurons simplement √† passer en revue les arguments d'entr√©e du constructeur.

### Structure du constructeur

Le constructeur de SNMPRequestHandler a la structure suivante :

```python
def __init__(
    self,
    address: str,
    name: str = '',
    requests: Optional[List[Dict[str, Any]]] = None,
    version: int = 2,
    community: str = 'public',
    username: str = '**username**',
    auth_protocol: str = 'MD5',
    auth_password: str = 'Col4Emd5',
    priv_protocol: str = 'AES',
    priv_password: str = 'Col4Eaes',
    port: int = 161,
    timeout: int = 1,
    retries: int = 1,
    options: Optional[Dict[str, Any]] = None,
    logger=None
) -> None:
```

Comme vous pouvez le voir, la plupart des champs sont li√©es √† la configuration du protocole SNMP ou des couches inf√©rieures.

**address :**
String. Adresse IP de la cible au format standard "10.90..".

**name :**
String. Nom descriptif de l‚Äôinstance. On pourra par exemple mettre le NAME de la machine. Sert en fait uniquement √† personnaliser les logs. Un nom par d√©faut sera g√©n√©r√© si vous n'en fournissez pas.

**version :**
Int. Version du protocole SNMP √† utiliser (2, 3).

**community :**
String. Cha√Æne de communaut√© SNMP. Ignor√© si version=3.

**username :**
Nom d‚Äôutilisateur SNMPv3.

**auth_protocol :**
Protocole d‚Äôauthentification SNMPv3 (`MD5`, `SHA`, etc.). L'ensemble des protocoles disponibles est visible dans un dictionnaire en haut du fichier `layers/request_handler/SNMPRequestHandler.py`.

**auth_password :**
Mot de passe pour l‚Äôauthentification SNMPv3.

**priv_protocol :**
Protocole de chiffrement SNMPv3 (`AES`, `DES`, etc.). L'ensemble des protocoles disponibles est l√† encore visible dans un autre dictionnaire en haut du fichier `layers/request_handler/SNMPRequestHandler.py`.

**priv_password :**
Mot de passe pour le chiffrement SNMPv3.

**port :**
Int. Port SNMP de la cible (par d√©faut 161).

**timeout :**
Int. Dur√©e maximale d‚Äôattente d‚Äôune r√©ponse (secondes).

**retries :**
Int. Nombre de tentatives en cas d‚Äô√©chec.

**options :**
Dictionnaire d‚Äôoptions suppl√©mentaires. Ce dictionnaire est compl√©tement libre, mais dans ce code, on y renseigne en g√©n√©ral un champ username et un champ id.
Le principal int√©r√™t de ce champ est d'int√©ragir avec une m√©thode de l'instance, `load`. Cette m√©thode est appel√©e pour chaque √©l√©ment pass√© en entr√©e de SNMPRequestHandler. Si l'√©l√©ment est un string, et qu'il a le format \_\_label\_\_, `load` va v√©rifier si le champ `options` contient l'√©tiquette `username`. Si c'est le cas, elle remplace la valeur du champ par la valeur dans le champ `options`.

**requests :**
Le champ requests est le seul un peu sp√©cifique. Il doit avoir un format tr√®s pr√©cis, √† savoir le suivant :

    [
        {
            'oid': '1.3.6.4.2.12.134',
            'metric_name': 'metrique_1',
            'operators': 'operateur_1'
        }, // pour chaque oid √† contacter, la liste doit contenir un dictionnaire de ce type
        ...
    ]

Vous pouvez ne pas fournir de champ operators. Ce champ n'est d'ailleurs jamais utilis√© directement par SNMPRequestHandler, il ne sert que lors de l'enregistrement en base pour MySQLManager. Il est pr√©sent ici car, d'un point de vu m√©tier, il semble plus logique d'associer l'operateur √† l'oid ou √† la metrique.
Vous pouvez √©galement ne pas fournir de champ 'metric_name'. La requ√™te se fera quand-m√™me, mais la donn√©e sera enregistr√©e dans un champ sp√©cifique, et ne sera pas prise en compte lors de l'enregistrement en base si vous passez votre SNMPRequestHandler √† un MySQLManager.
Le programme ignorera les metriques qui n'ont pas d'oid.

**logger :**
Instance de logger pour les messages et avertissements, comme pour les autres constructeurs de classe.

Les autres m√©thodes importantes de SNMPRequestHandler ne prennent pas d'argument. Ainsi, vous pouvez simplement appeler .run() pour lancer la collecte une fois l'instance initialis√©e.

Il y a cependant un dernier point √† √©voquer sur cette classe.

### point sur la m√©thode update_results

Cette m√©thode est celle qui g√®re la jointure entre oid et metrique quand c'est n√©cessaire, et qui fait un premier formatage des donn√©es.
Ce qu'il y a d'important √† dire sur cette m√©thode, c'est que c'est celle qu'on va vouloir r√©√©crire si on veut changer les fonctionnalit√©es de SNMPRequestHandler. Ainsi, pour la v√©rification des tables d'alarme, j'ai r√©utilis√© le m√™me code mais r√©√©cris cette m√©thode pour lui permettre de g√©rer la reconnaissance d'oids sp√©cifiques dans des arbres plus complexes, donc en changeant le pr√©-traitement effectu√© par cette m√©thode. En particulier, dans ce cas pr√©cis, j'ai cr√©√© deux autres m√©thodes pour huawei et vertiv qui g√®rent la gestion des arbres d'oid propres √† leur constructeur. Vous trouverez les d√©tails sur cette m√©thode dans `domain/alarm_monitor/SNMPAlarmRequestHandler.py`.

## Gestion des traps et des alarmes

En plus de l'ensemble des dossiers et fichiers de code √©voqu√©s ci-dessus, vous trouverez dans layers les dossiers alarms_manager et event_listener. Ces deux fichiers sont en fait li√©s √† la gestion des alarmes et des traps.

### Gestion des traps

La gestion des traps n'est pas aussi "standardis√©e" que les op√©rations de requ√™tage et d'enregistrement en base, et beaucoup de choses se font au niveau de domain. En fait, les traps d√©pendent surtout de event_listener, dont nous parlons juste en-dessous.

Pour le reste, le fichier principal de gestion des traps est `domain/traps_and_alarms/prcess_trap.py`. Je reviens dessus rapidement juste apr√®s.

### point sur event_listener

event_listener est une classe d'√©coute de trap, bas√© sur pysnmp (qui, √† partir d'une tram UDP, et capable de construire une trap SNMP). Elle a le constructeur suivant :

```python
__init__(self, device_configs: List[Dict[str, Any]], listen_address="0.0.0.0", port=162, trap_callback: Optional[Callable] = None)
```

listen_address et port servent √† d√©finir les trams IP et UDP sur lesquelles on √©coutera. Il n'y a √† priori aucunes raisons de les modifier. Pr√©cisons si besoin que des services d'√©coute de ce type construisent toujours leur tram IP avec l'adresse 0.0.0.0 pour recevoir toutes les trams IP (sauf si on veut √©couter une machine tr√®s sp√©cifique, au quel cas on pourra √©ventuellement mettre l'IP de la machine).

device_configs est une liste de dictionnaire, o√π chaque dictionnaire contient une configuration SNMP d'une machine que l'on veut superviser. Le format correspond (volontairement) au format d'entr√©e de SNMPRequestHandler, √† savoir :

    {
        'version': ..
        'community': ..
        'username': ..
        'auth_protocol': ..
        'auth__password': ..
        'priv_protocol': ..
        'priv_password': ..
        'engine_id': .. // on doit fournir en plus un engine_id
    }

Enfin, trap_callback attend une fonction. C'est en pratique dans cette fonction que le reste va op√©rer. SNMPTrapListener r√©ceptionne et d√©chiffre les traps, puis appelle trap_callback en lui passant en entr√©e un dictionnaire au format :

    {
        '1.3.6.1..': 'valeur associe a cet oid',
        ...
    }

### Compl√©ment sur la gestion des traps

La suite de la logique li√©e √† la gestion des traps se fait dans `domain/traps_and_alarms/process_trap.py`, qui contient la fonction process_trap, fonction qui est pass√©e √† event_listener.

Les traps renvoient un arbre d'OID avec plusieurs feuilles, donc plusieurs valeurs. L'id√©e est d'enregistrer ces valeurs comme une seule entr√©e (ligne) dans une table. C'est ce que fait process_trap.

Cette fonction se base sur les donn√©es dans la table TRAPS pour effectuer un certain nombre de traitement. Pr√©cisement, elle appelle la fonction generate_results dans `domain/traps_and_alarms/generate_results.py`, qui s'occupe de r√©cup√©rer les donn√©es dans la table de TRAPS, et d'appliquer des op√©rateurs aux donn√©es, puis de les reformater au format standard attendu MySQLManager. process_trap r√©cup√®re alors le data g√©n√©r√©, et le passe ensuite √† une instance de MySQLManager pour l'enregistrer en base.

process_trap (comme son nom, certe, ne l'indique pas) g√®re aussi les alarmes. Elle appelle pour √ßa la fonction process_alarm (dans `domain/traps_and_alarms/process_alarm.py`) qui prend en entr√©e la donn√©e des traps, la retraite un peu (le format des traps et des alarmes diff√©re tr√®s l√©g√®rement), et utilise AlarmManager pour mettre √† jour les alarmes √† partir de ces donn√©es.

### Parent√®se sur les op√©rateurs des traps

Comme √©voqu√© juste au-dessus (et comme vous pouvez le voir dans l'interface historica d√©di√©e aux traps) il existe un syst√®me d'op√©rateur pour les traps.
Ce syst√®me d'op√©rateur est ind√©pendant de celui de MySQLManager, et prend effet en amont. Il est g√©r√© dans la fonction generate_results.
Les op√©rateurs sont import√©s depuis le fichier `operators/trap_operators.py`. Ainsi, si vous voulez rajouter un op√©rateur, il suffit de rajouter une fonction dans ce fichier, nomm√© avec le nom que vous voulez donner √† votre op√©rateur.

## Gestion des alarmes (round 2)

Nous avons √©voqu√© la classe AlarmManager dans la section pr√©c√©dente. En fait, cette classe est d√©finie dans le dossier `layers/alarm_manager`. C'est une classe sp√©cialis√©e dans l'enregistrement des alarmes en base.

Dans la suite de cette partie, nous rentrons plus en d√©tail dans le fonctionnement de la gestion des alarmes.

Commen√ßons par quelques √©l√©ments sur la logique de gestion des alarmes.

Du point de vue de Centaure, la gestion des alarmes consiste principalement en une gestion fine (ajout ou modification) des donn√©es en base.

Il n'y a pas de moyens formel pr√©cis pour r√©cup√©rer les donn√©es des alarmes pr√©vu par Centaure (tout est g√©r√© dans domain, comme c'est le cas de la gestion des traps d√©crite dans la partie pr√©c√©dente), et ceci principalement parce qu'il existe plusieurs approches pertinentes pour r√©cup√©rer des donn√©es d'alarme, √† savoir notamment :

- On peut se baser sur des listes d'OID donnant le statut des alarmes qu'on souhaite surveiller et r√©cup√©rer ces donn√©es √† intervalle r√©gulier (on pourra alors utiliser la classe Scrapper).
- On peut r√©cup√©rer les donn√©es des tables d'alarme actives, que beaucoup de constructeurs proposent (on pourra √©galement utiliser la classe Scrapper dans ce cas, √† condition de faire quelques modifications dans une version personnalis√©e de la classe SNMPRequestHandler). C'est l'une des solutions adopt√©es dans le code.
- on peut utiliser des OID de surveillance fournies dans les traps. Certains constructeurs renvoient en effet dans la trap un OID qui permet de conna√Ætre l'√©tat de l'alarme qui a lev√© la trap ou de v√©rifier qu'elle est toujours active.
- enfin on peut tout simplement se baser sur les traps elles m√™me, en activant l'alarme quand on re√ßoit une trap d'activation, ou en d√©sactivant l'alarme si c'est une trap off. Cette approche est √©galement utilis√©e dans la version SFR, et a d√©j√† √©t√© d√©crite plus haut.

  Il est probablement en pratique pertinent de cumuler plusieurs approches (et ce que ne font pas, d'ailleurs, la plupart des outils de supervision !) car elles ont chacunes leurs avantages et leurs inconv√©nients, et plus simplement parce qu'il est compliqu√© d'obtenir toutes les alarmes avec une seule approche. On pourra alors faire plusieurs services g√©rant chacun les alarmes de mani√®re asynchrone et d√©cor√©l√©, mais en passant syst√®matiquement par la m√™me classe (AlarmManager).

  Comme √©voqu√© pr√©c√©demment, Centaure ne g√®re pas directement de mani√®re standardis√©e la r√©cup√©ration et la standardisation des donn√©es pour les alarmes. Il impose cependant que les donn√©es en base contiennent un √©l√©ment ref, et un √©l√©ment alarme_active. Les alarmes sont g√©r√©es par les alarm_manager, qui sont des classes h√©ritant √† la fois de BaseAlarmManager, et d'un DatabaseManager capable de g√©rer des op√©rations d'√©criture, lecture, et modifications en base. On obtiens ainsi une nouvelle classe capable de r√©aliser l'op√©ration "treat". Cette op√©ration ajoute et/ou insert en base des donn√©es de mani√®re conditionnelle : elle modifie la donn√©e si celle-ci est pr√©sente en base mais que le champ alarme_active n'a pas la m√™me valeur qu'en entr√©e, et insert la donn√©e en base si celle-ci n'est pas d√©j√† pr√©sente avec le champ alarme_active √† 1.

Mais comment le code arrive √† lier les donn√©es en entr√©e avec les donn√©es en base ? Comment sait-on qu'une alarme est active en base ?
C'est en utilisant l'argument ref : ref est un bigint permettant d'identifier de mani√®re unique un type d'alarme. Cet argument peut √™tre fourni par la trap. Certains constructeurs associent en effet une ref √† chaque type d'alarme existante pour leur √©quipement. Cette ref sert suite d'identifiant de l'alarme : il ne peut pas y avoir 2 alarmes avec la m√™me ref active en base (donc avec le champ alarme_active √† 1). Logiquement, le constructeur du mat√©riel supervis√© ne devrait pas permettre √† deux alarme avec la m√™me ref d'√™tre active en m√™me temps sur son √©quipement.
En pratique les constructeurs ne transmettent pas toujours la ref des alarmes, que ce soit via les traps au via de la collecte directe (requ√™te snmpget sur l'√©quipement). Il peut donc √™tre pertinent d'utiliser un autre √©l√©ment envoy√© par les √©quipements pour g√©n√©rer soi-m√™me les ref. Les √©quipements renvoient par exemple presque toujours un string unique √† l'alarme, contenant des informations en clair sur la nature de l'alarme (et qui est parfois personnalisable). Il peut √™tre pertinent utiliser ce string (ou un autre) pour g√©n√©rer une ref unique √† un type d'alarme. La biblioth√®que contient d'ailleurs une fonction generate_ref qui permet de g√©n√©rer un bigint unique √† partir d'un string. C'est cette approche qui est utilis√©e dans ce code. Elle a l'√©norme avantage d'√™tre g√©n√©ralisable √† plusieurs constructeurs dont les formats de traps et d'alarme varient.
Il existe probablement beaucoup d'autres mani√®res pertinentes de g√©n√©rer et g√©rer les refs. Vous pouvez toujours personnaliser librement les refs, tant que vous fournissez un √©l√©ment 'ref' pour chaque alarmes en entr√©e des AlarmManager.

Un exemple de code pour finir ?
En fait, il n'y a pas grand chose √† dire de plus car MySQLAlarmManager s'utilise exactement comme MySQLManager. Voyez l'exemple ci-dessous :

```python
recorder = MySQLAlarmManager(
    SNMPAlarmRequestHandler(address, name=name, requests=requests, **config, options=machine_data, logger=self.logger), # une classe h√©ritant de SNMPRequestHandler, et qu'on aura modifier pour qu'elle nous renvoie toutes les donn√©es voulues. On aurait aussi tr√®s bien pu fournir un champ data.
    table_struct=['ref', 'equipement', 'info', 'message_erreur', 'alarme_active', 'start_time', 'end_time'], # une structure possible des alarmes en table
    logger=self.logger # le logger
)

recorder.object.run() # on r√©cup√®re les donn√©es des alarmes sur l'√©quipement via SNMPRequestHandler
recorder.treat() # la seule particularit√© de MySQLAlarmManager : on peut utiliser la m√©thode treat, qui va donc enregistrer les donn√©es en base si leur ref ne correspond √† aucune alarme active, et qui va modifier les alarmes actives sinon, en fonction de la valeur du champ alarme_active.
```

Dans notre cas, pour la gestion des alarmes, on a envi d'√©galement faire une chose en plus :
On veut g√©n√©rer le dictionnaire exacte des alarmes √† mettre √† off ou √† activer, √† partir des alarmes qu'on a r√©cup√©r√©s comme active sur l'√©quipement, et en les comparant aux alarmes r√©ellement actives dans notre base. On rajoute pour cela une m√©thode `merge_fetched_with_results` dans la classe MySQLAlarmManager, qui va comparer les valeurs dans data (donc les valeurs r√©cup√©r√©es par l'instance de RequestHandler), et les valeurs de fetched_data (donc des valeurs qu'on r√©cup√®re en base) pour d√©finir les modifications √† faire en base. Avec cette nouvelle m√©thode, on peut ainsi utiliser le code suivant :

```python
recorder = MySQLAlarmManager(
    SNMPAlarmRequestHandler(address, name=name, requests=requests, **config, options=machine_data, logger=self.logger), # une classe h√©ritant de SNMPRequestHandler, et qu'on aura modifi√© pour qu'elle nous renvoie toutes les donn√©es voulues. On aurait aussi tr√®s bien pu fournir un champ data.
    table_struct=['ref', 'equipement', 'info', 'message_erreur', 'alarme_active', 'start_time', 'end_time'], # une structure possible des alarmes en table
    logger=self.logger # le logger
)
recorder.object.run() # on r√©cup√®re les donn√©es des alarmes sur l'√©quipement via SNMPRequestHandler

recorder.fetch(where = "alarme_active = 1") # on r√©cup√®re les alarmes actives en base

recorder.merge_fetched_with_results() # si une alarme renvoy√©e par l'√©quipement n'est pas dans la base, on la laisse pour qu'elle soit activ√©e, et si une alarme active en base n'est pas renvoy√©e par l'√©quipement, c'est qu'elle n'est probablement plus active, donc on la rajoute avec alarme_active = 0 (et un end_time). On remplace ensuite data par cette nouvelle valeur avec la m√©thode set_data()

recorder.treat() # on effectue les treat, qui va cette fois op√©rer sur les donn√©es "merg√©s", donc √©ventuellement passer √† off certaines alarmes
```

En pratique, c'est ce code qui est utilis√©, mais il est exploit√© dans la classe AlarmSNMPScrapper (qui h√©rite de SNMPScrapper). Vous pouvez consulter le code dans `domain/alarm_monitor` pour plus de d√©tails.

## alerter

Les alerteurs (ou alerters dans le code) sont un ensemble de classe capable de r√©cup√©rer des donn√©es en base, v√©rifier un certain nombre de condition sur ces donn√©es, et, si les conditions sont v√©rifi√©es, envoyer des emails.

La classe principale est `layers/alerter/MySQLAlerter.py`. Cette classe h√©rite de BaseScrapper, et r√©cup√®re donc certaines des m√©thodes des scrappers.

MySQLAlerter g√®re l'ensemble des v√©rifications li√©es √† une alerte. Une alerte peut porter sur plusieurs machines, et la classe v√©rifiera alors les conditions de l'alerte sur toutes les machines demand√©es. Voyons ses arguments d'entr√©e :

```python
    def __init__(self, conditions: Union[List[Dict], str], name: str = 'alerter', machines: Union[List[str], str] = [], construct: str = "", limit_date: int = 0, emails: Union[List[str], str] = [], logger: logging.Logger = None)
```

**name :** C'est un nom, qui aparaitra dans certains logs d'erreur et dans l'email envoy√© le cas √©ch√©ant. Il n'a aucunes autres influence sur l'execution du code.

**machines :** C'est une liste de string (les noms des machines tel qu'indiqu√© dans historica). La classe va r√©cup√©rer en interne les donn√©es li√©es √† ces machines depuis la base historica, principalement l'ID, et r√©cup√©rer les donn√©es correspondant √† ces machines en base.

**construct :** String. Vous pouvez renseigner un constructeur plut√¥t que des noms de machine en base. Toutes les machines li√©es √† ce constructeur seront alors r√©cup√©r√©es. Vous devez renseigner exactement le champ construct indiqu√© en base (il n'y a aucun traitement particulier fait sur ce champ). Notez que si vous fournissez un constructeur et un champ machines, la requ√™te r√©cup√©rera tout ce qui correspond √† l'un des deux param√®tres au moins.

**limit_date :** Attend un timestamp UNIX (donc un int). C'est une des conditions sur les donn√©es en base. Si vous indiquez un timestamp correspondant √† l'heure courant moins 6 heures, l'alerteur v√©rifiera vos conditions sur toutes les donn√©es en base sur les 6 derni√®res heures.

**emails :** Liste de str, ou str si un seul email ou si une liste d'email s√©par√© par des ','. Si l'alerte est d√©clanch√©e, l'email sera envoy√© √† tout les emails renseign√©s dans ce champ.

**conditions :** List ou JSON (string au format JSON). Contient une liste du type :

    [
        {
            "metrique":"phase_1_courant ; phase_2_courant ; phase_3_courant",
            "type_condition":"seuil",
            "valeur_max":"100",
            "valeur_min":"",
            "valeur_egale":"",
            "valeur_differente":"2147483647",
            "nombre_valeurs_seuil":1,
            "logic_operator":"ET"
        },
        ...
    ]

Ce JSON contient en fait la liste des conditions de d√©clanchement de l'alerte, avec pour chaque condition toutes les informations n√©cessaires pr√©cisant la nature de l'alerte. Si vous voulez des pr√©cisions sur chaque champ, consultez la page historica des alertes.

Cette classe est la plus r√©cente, et je n'ai donc pas eu de raison pour l'instant de "g√©n√©raliser" son fonctionnement. Ainsi, elle est pr√©vue pour fonctionner dans le cadre d'un code sp√©cifique uniquement :

```python
def get_past_timestamp(heures=0, jours=0, semaines=0):
    """
    Retourne le timestamp (int) correspondant √† la date/heure actuelle
    moins le nombre d'heures, jours et semaines fourni.

    :param heures: Nombre d'heures √† soustraire
    :param jours: Nombre de jours √† soustraire
    :param semaines: Nombre de semaines √† soustraire
    :return: Timestamp UNIX (int)
    """
    maintenant = datetime.now()
    delta = timedelta(hours=heures, days=jours, weeks=semaines)
    date_calculee = maintenant - delta
    return int(date_calculee.timestamp())

def get_alerter(name):
    """
    R√©cup√®re les informations de l'alerteur 'name' dans la table ALERTEURS
    et retourne un dictionnaire avec les infos cl√©s.
    """

    conn = mysql.connector.connect(**ae_db_config)
    cursor = conn.cursor(dictionary=True)

    query = """
        SELECT nom, constructeur, ae_specifiques, conditions, emails, semaines, jours, heures
        FROM ALERTEURS
        WHERE active = 1 AND nom = %s
    """
    cursor.execute(query, (name,))
    row = cursor.fetchone()

    cursor.close()
    conn.close()

    if not row:
        return None # Aucun r√©sultat trouv√©

    timestamp = get_past_timestamp( # Calcul du timestamp limite
        heures=row['heures'] or 0,
        jours=row['jours'] or 0,
        semaines=row['semaines'] or 0
    )

    return {
        'name': row['nom'],
        'construct': row['constructeur'],
        'limit_date': timestamp,
        'emails': row['emails'],
        'conditions': row['conditions']
    }

if __name__ == "__main__": # le code principal est ici
    alerter_info = get_alerter("phase haute") # on r√©cup√®re un alerteur appel√© "phase haute" ici
    alerter = MySQLAlerter(**alerter_info, logger = logger)
    alerter.check() # on lance la v√©rification avec check, qui enverra √©galement un email le l'alerte est d√©clanch√©e
```

Si vous voulez maintenant v√©rifier et d√©clancher toutes les alertes en base, il suffit de modifier get_alerter pour qu'il renvoit toutes les alertes en base plut√¥t qu'une seule sp√©cifique. 

Dans la pratique, la fonction get_alerter est dans `domain/alerter/get_alerter.py`.

## process_manager

Le dernier dossier pr√©sent dans layers et qui n'a pas encore √©t√© √©voqu√© est process_manager.
Il y a dans ce dossier plusieurs outils pour g√©rer des process. En fait, comme les op√©rations de collecte sont longues, on voudra parfois faire en sorte qu'une nouvelle collecte ne puisse pas se lancer tant que l'encienne n'est pas termin√©e. Le but √©tant de ne pas surcharger la RAM du serveur faisant tourner le script, en faisant tourner 5, 10, 30 fois le m√™me script en parall√®le. Ce besoin est d'autant plus important que de nombreuses classes de centaure sont assez gourmandes en RAM.
Voici donc quelques exemples permettant d'utiliser ce code :

```python
from layers.process_manager.manage_processes import has_active_processes_in_list, add_pid_to_list, remove_pid_from_list
import os

if has_active_processes_in_list(): # permet de v√©rifier si un autre processus est d√©j√† actif
        print("Arret de l'execution : un autre processus est actif.")
        sys.exit()

pid = os.getpid()
add_pid_to_list(pid)

# executez ici le code voulu

remove_pid_from_list(pid)
```

Vous pouvez √©galement imposer une limite au nombre de process actif en m√™me temps avec `howmany_pid_in_list`:

```python
from layers.process_manager.manage_processes import has_active_processes_in_list, add_pid_to_list, howmany_pid_in_list, remove_pid_from_list
import os

K = 5 # le nombre de process actif en m√™me temps, personnalisable
if has_active_processes_in_list() and howmany_pid_in_list() > K: # on rajoute une condition ici
    print(f"Arret de l'execution : {K} autres processus actifs.")
    sys.exit()

pid = os.getpid()
add_pid_to_list(pid)

# executez ici le code voulu

remove_pid_from_list(pid)
```

> Notez que tout les process que vous passez √† cette fonction et qui sont encore actifs sont pris en compte.

> Il n'est pas dramatique d'oublier d'appeler remove_pid_from_list, c'est m√™me obstionnelle. En fait, has_active_processes_in_list v√©rifie si les process renseign√©s sont encore actifs. C'est √©galement pour √ßa que je vous conseille de toujours appeler has_active_processes_in_list, m√™me si vous ne voulez utiliser que howmany_pid_in_list, car ce dernier ne fait pas de v√©rification.

> Vous trouverez dans le m√™me fichier la fonction kill_process_in_list, qui permet tout simplement de forcer l'arr√™t de tout les process actifs renseign√©s.

Et.. c'est tout pour process_manager !
